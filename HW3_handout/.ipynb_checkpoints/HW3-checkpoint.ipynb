{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d5d934df9310d9448cdffe1bc2e8a65b",
     "grade": false,
     "grade_id": "cell-e009fd0eb7f5e1d2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Homework 3 â€” (20 points)\n",
    "======\n",
    "### What to hand in\n",
    "You are to submit the following things for this homework:\n",
    "1. A Jupyter notebook containing all code and output (figures and audio). I should be able to evaluate the file to reproduce all output. \n",
    "1. Any other data that we tell you to save to a file (e.g. audio files).\n",
    "\n",
    "Note: Make sure to include all the files that are required for the notebook to run **from the submission folder** (e.g. police_noisy.wav). Points will be taken off from submissions that crash because Python cannot find the specified files.\n",
    "\n",
    "### How to hand it in\n",
    "To submit your lab:\n",
    "1. Compress all of the files specified into a .zip file. \n",
    "1. Name the file in the following manner, firstname_lastname_hw1.zip. For example, Bryan_Pardo_hw3.zip. \n",
    "1. Submit this .zip file via Canvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b8f800d35efe498eed6ee4533dd570f2",
     "grade": false,
     "grade_id": "cell-5750646bd03c744f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# *Please write down your name here* =>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "652cd739ad95e12843908165f5ecccc6",
     "grade": false,
     "grade_id": "cell-ecdcdda315b6289b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Run this code block 1st, to import the needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This line is a convenience to import most packages you'll need. You may need to import others (e.g. random and cmath)\n",
    "import IPython, numpy as np, scipy as sp, matplotlib.pyplot as plt, matplotlib, sklearn, librosa, cmath,math, csv\n",
    "from IPython.display import Audio\n",
    "from sklearn.datasets import load_iris\n",
    "# This line makes sure your plots happen IN the webpage you're building, instead of in separate windows.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "97748a180cc4703509d35c8215fc859d",
     "grade": false,
     "grade_id": "cell-0178910fb5907927",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## IMPLEMENT DISTANCE MEASURES\n",
    "\n",
    "#### 1. (1 point) Implement a distance measure that takes two numpy arrays and an a positive scalar as input  and returns a distance measure between these two numpy arrays based on a generalized P-norm (AKA L-norm)  (e.g. P = 1 means Manhattan distance, P = 2 is Euclidean). The only library you may use to write this function is numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "13e510ef3a593f7e1e7422d3b4a2cf6d",
     "grade": false,
     "grade_id": "cell-52f83b00186467f7",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def p_norm_distance(x, y, p):\n",
    "    \"\"\"\n",
    "    Takes a pair of numpy arrays, applies the appropriate p-norm distance measure to them and outputs it.\n",
    "    \n",
    "    Input Parameters\n",
    "    ----------------\n",
    "    x: a 1D numpy array of a feature vector\n",
    "    y: a 1D numpy array of a feature vector\n",
    "    p: integer, If 1, use Manhattan distance. If 2, use Euclidean distance\n",
    "                \n",
    "    Returns\n",
    "    -------\n",
    "    distance: a non-zero scalar, representing the distance between x and y\n",
    "    \"\"\"\n",
    "    \n",
    "    if p == 1:\n",
    "        distance = np.linalg.norm(x - y, ord=1)\n",
    "    elif p == 2:\n",
    "        distance = np.linalg.norm(x - y, ord=2)\n",
    "    \n",
    "#     raise NotImplementedError # delete this line when you add your solution\n",
    "\n",
    "    return distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = np.array([1,2])\n",
    "# y = np.array([3,4])\n",
    "# p_norm_distance(x, y, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c8ae637208c16cc6801287a3d025b9e1",
     "grade": true,
     "grade_id": "cell-2e6b64e1416a17c0",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# you can leave this cell blank - it's for the auto-grader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "16acd7fb51852ea165f07a07018c4a96",
     "grade": false,
     "grade_id": "cell-ea1fd9c66062c9a1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### 2. (1 point) Create two sets of test cases that run your code from the previous question and illustrate it works correctly. The test cases include one for Manhatten distance and the other for euclidean distance. Compare your implementation with distance functions provided in the Scipy package:\n",
    "\n",
    "* Manhattan diatance: [scipy.spatial.distance.cityblock](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.spatial.distance.cityblock.html) \n",
    "* Euclidean distance: [scipy.spatial.distance.euclidean](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.spatial.distance.euclidean.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "cc4c4edd355b6a3f6e48930196fbd305",
     "grade": true,
     "grade_id": "cell-f2f0588088042c43",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# raise NotImplementedError # delete this line when you add your solution\n",
    "\n",
    "x = np.array([1,2,3,4,5])\n",
    "y = np.array([6,7,8,9,10])\n",
    "\n",
    "print(p_norm_distance(x, y, 1) == sp.spatial.distance.cityblock(x,y))\n",
    "print(p_norm_distance(x, y, 2) == sp.spatial.distance.euclidean(x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "328eb7875fca0a00d9226c2e101bb019",
     "grade": false,
     "grade_id": "cell-b94f42c35ead5da4",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### 3. (1 point) Implement a distance measure that takes two vectors as input and returns the cosine distance between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "eac97089a76e47515fae96a0fc3cf191",
     "grade": false,
     "grade_id": "cell-eca41a1e79a92c27",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def cosine_distance(x, y):\n",
    "    \"\"\"\n",
    "    Takes a pair of numpy arrays, applies cosine distnace between them.\n",
    "    \n",
    "    Input Parameters\n",
    "    ----------------\n",
    "    x: a 1D numpy array of a feature vector\n",
    "    y: a 1D numpy array of a feature vector\n",
    "                \n",
    "    Returns\n",
    "    -------\n",
    "    distance: the cosine distance between x and y\n",
    "    \"\"\"\n",
    "    \n",
    "    x_y_dot = np.dot(x, y)\n",
    "    sqrt_sum_x = np.linalg.norm(x)\n",
    "    sqrt_sum_y = np.linalg.norm(y)\n",
    "\n",
    "    \n",
    "    distance = x_y_dot / (sqrt_sum_x * sqrt_sum_y)\n",
    "    distance = 1 - distance\n",
    "    \n",
    "#     raise NotImplementedError # delete this line when you add your solution\n",
    "    \n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f60afd907c4fc38f3e624921cfb3140d",
     "grade": true,
     "grade_id": "cell-71161d6353946d6f",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# you can leave this cell blank - it's for the auto-grader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "81e32bb41f01c7ea7fed186ff6d098e4",
     "grade": false,
     "grade_id": "cell-fb2d4ff5e997eea0",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### 4. (1 point) Create two sets of test cases that run your code from the previous question and illustrate it works correctly. Compare your implementation with distance functions provided in the Scipy package:\n",
    "\n",
    "* Cosine diatance: [scipy.spatial.distance.cosine](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.spatial.distance.cosine.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "36df5f3801d584182649a99363bff4ab",
     "grade": true,
     "grade_id": "cell-ae9fe4f36d81fd8a",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# raise NotImplementedError # delete this line when you add your solution\n",
    "\n",
    "x = np.array([1,2,3,4,5])\n",
    "y = np.array([6,7,8,9,10])\n",
    "z = np.array([21,324,6785,546,143])\n",
    "\n",
    "print(sp.spatial.distance.cosine(x,y) == cosine_distance(x,y))\n",
    "print(sp.spatial.distance.cosine(y,z) == cosine_distance(y,z))\n",
    "print(sp.spatial.distance.cosine(x,x) == cosine_distance(x,x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "946f5d4dd165d3f3b82d31927421257d",
     "grade": false,
     "grade_id": "cell-98195f6a5367c49a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### 5. (1 point) Describe an example situation where Cosine distance would be preferable to Euclidean distance. We want two parts to this: First, explain a fundamental property where Cosine distance differs from Euclidean. Second, give an example situation (relating to audio) where that property would be an advantage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "1bc39c05007227cbfb552dc12db72104",
     "grade": true,
     "grade_id": "cell-c78f41e8f53b0b81",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "Part one: cosine similarity/distance only focuses on if two vectors are similar. It normalizes the vectors as an integral part of calculating the cosine distance. Eucledian distance does not offer any sort of helpful scaling or normalization. \n",
    "\n",
    "Part two: If there were two audio files of the same exact song, but one was much louder than the other, euclidean distance would fail. It would show a large difference/distance between these two files, because there is not any feature scaling done in finding eucledian distance. Cosine similarity offers an immunity to scaling differences like this, because it only cares that these two vectors are similar or \"pointing in the same direction\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPLEMENT A K-NEAREST NEIGHBOR CLASSIFIER\n",
    "\n",
    "#### 6. (2 points) Implement a K-nearest-neighbor classifier that can use either Euclidean distance or Cosine distance. (Use the Scipy package for distance meatures)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "6c7e0a3a8f1e5e23c7e57e760da8d044",
     "grade": false,
     "grade_id": "cell-a1443bbaecc1b976",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def knn(data_X, data_Y, query_X, dist_measure, k):\n",
    "    \"\"\"\n",
    "    Takes a data set of examples encoded as feature vectors, along with the label for each example in the data. \n",
    "    It also takes in a set of queries, for which we want to know the labels. It finds the distance from each \n",
    "    query_X to each example in data_X. It returns a label for each example in query_X by picking the most \n",
    "    popular label from the k nearest neighbors in data_X. Distance is determined by the selected distance metric.\n",
    "    \n",
    "    Input Parameters\n",
    "    ----------------\n",
    "    data_X: a 2-D numpy array with a shape of (the number of examples in the data, the number of features).\n",
    "    data_Y: a 1-D numpy array containing integer labels for the examples in data_X. \n",
    "            The labels should be encoded as integer values BEFORE they are passed this function.\n",
    "            (E.g., [class1, class1, class2, class1] ==> [0, 0, 1, 0])\n",
    "    query_X: a 2-D numpy array with a shape of (the number of query examples, the number of features). \n",
    "            Note, the query_X must have the same number of features, in the same order as the data_X \n",
    "    dist_measure: a string determining which distance measure to use. ('euclidean' or 'cosine')\n",
    "    k: the number of nearest neighbors in the data to consider, when labeling a query\n",
    "    \n",
    "    Returns\n",
    "    ----------------\n",
    "    query_Y: a 1-D numpy array of integer values referring to predicted labels for the set of queries\n",
    "    \"\"\"\n",
    "    \n",
    "    # nested for loop\n",
    "    # for each query,\n",
    "        # for each vector in train_x,\n",
    "            # check query distance to each train_X vector and\n",
    "            # store the distance between each query in a vector the same size as train_Y\n",
    "        # in a vector the height of (#vecs in) query_X store the label that matches the index of the smallest number\n",
    "    # return\n",
    "    \n",
    "    query_Y = []\n",
    "        \n",
    "    for q_x in query_X: # check each query \n",
    "        k_smallest = np.array([])\n",
    "        distances = np.array([])\n",
    "        for t_x in data_X: # against each training datum\n",
    "            if dist_measure == \"euclidean\":\n",
    "                dist = sp.spatial.distance.euclidean(q_x, t_x)\n",
    "                distances = np.append(distances, dist) # append the euclidean distance between query and datum\n",
    "            elif dist_measure == \"cosine\":\n",
    "                dist = sp.spatial.distance.cosine(q_x, t_x)\n",
    "                distances = np.append(distances, dist) # append the cosine distance \"\"\n",
    "        \n",
    "        # grab smallest k\n",
    "        for i in range(k):\n",
    "            min_dist_ind = np.argmin(distances) # index of min distance\n",
    "            k_smallest = np.append(k_smallest, min_dist_ind) # track indices\n",
    "            distances[min_dist_ind] = np.argmax(distances) + 1 # reset so it is no longer min, but don't change sizing\n",
    "        k_smallest = k_smallest.astype(int)\n",
    "        for i in range(len(k_smallest)):\n",
    "            k_smallest[i] = data_Y[k_smallest[i]] # go from index of label in data_Y to label in data_Y\n",
    "        \n",
    "        query_Y.append(np.bincount(k_smallest).argmax())  # grab the most common label, append to label array\n",
    "        \n",
    "    return query_Y\n",
    "    \n",
    "#     raise NotImplementedError # delete this line when you add your solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "aab8e33af290169e54f21741ac175324",
     "grade": true,
     "grade_id": "cell-1e7e081dd82b94ce",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# you can leave this cell blank - it's for the auto-grader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "55b72457afb3e75611ce38d7880a271c",
     "grade": false,
     "grade_id": "cell-dd0b482c2c08397d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### 7. (1 point) Generate a toy test case that would make different classification choices, depending on which metric (Euclidean or Cosine) you choose.  Before running the actual code, in this problem, you are going to classify test data by eye-balling it.\n",
    "\n",
    "1) Generate a training set of 10 data points with 2 features (i.e. 2-dimensional vectors) and 2 classes. The training set should include two numpy array: train_X of shape (10, 2) and train_Y of shape (10, ). train_Y contains 0 or 1 each of which indicates the first class and the second class.\n",
    "\n",
    "2) Plot the training set on 2-D feature space with color coded classes, so we can tell which one belongs to which class.\n",
    "\n",
    "3) Generate a test set of 3 data points with 2 features. The test set should include two numpy array: test_X of shape (3, 2). Plot them on the figure you created in the previous step. Use a color that was not used for the trainng set.\n",
    "\n",
    "4) Make sure the figure has a proper legend so we can tell which data points are training data of class1 or class2, or testing data.\n",
    "\n",
    "5) Perform KNN classification by eye-balling it (**K=3**). Tell the predicted class of each testing data point if you use Euclidean distance. \n",
    "\n",
    "6) Perform KNN classification AGAIN by eye-balling it (**K=3**). Tell the predicted class of each testing data point if you use Cosine distance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "ad5ff8da351613120afc78d3d7a7731a",
     "grade": true,
     "grade_id": "cell-8426109502145d91",
     "locked": false,
     "points": 0.5,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_X = np.array([[1,2], [3,3], [3,4], [4,4], [5,6], [30,20], [10,20], [20,30], [50,20], [30,10]]) #replace it with your training data \n",
    "train_Y = np.array([0,0,0,0,0,1,1,1,1,1]) # replace it with labels of your training data\n",
    "\n",
    "test_X = np.array([[7,7], [30,40], [5,2]]) # replace it with your testing data\n",
    "\n",
    "\n",
    "# your code to generate the plot goes here\n",
    "\n",
    "color_labels = ['green', 'cyan']\n",
    "\n",
    "plt_train_x,plt_train_y = train_X.T\n",
    "train_plt = plt.scatter(plt_train_x, plt_train_y, c=train_Y, cmap=matplotlib.colors.ListedColormap(color_labels))\n",
    "\n",
    "plt_test_x, plt_test_y = test_X.T\n",
    "\n",
    "test_plt = plt.scatter(plt_test_x, plt_test_y, color='orange')\n",
    "\n",
    "legend_elems = [matplotlib.lines.Line2D([0], [0], color='green', label='label 1'),\n",
    "                matplotlib.lines.Line2D([0], [0], color='cyan', label='label 2'),\n",
    "                matplotlib.lines.Line2D([0], [0], color='orange', label='test data')]\n",
    "plt.legend(handles=legend_elems)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# raise NotImplementedError # delete this line when you add your solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "4c34984db1cbea28861313289c4f2ff5",
     "grade": true,
     "grade_id": "cell-f7204e4e6b1ebb7a",
     "locked": false,
     "points": 0.5,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# The predicted labels of the testing data, given Euclidean distance, goes here\n",
    "test_Y_euclidean = np.array([0, 1, 0]) # replace these values with the right labels\n",
    "\n",
    "# The predicted labels of the testing data, given Cosine distance, goes here\n",
    "test_Y_cosine = np.array([0, 0, 0]) # replace these values with the right labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "57afdedc9845088d3332c8d71992ef7f",
     "grade": false,
     "grade_id": "cell-3c8fccf192fb6223",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### 8. (1 point) Test your implementation of KNN (K=3) with the training and testing set you generated from question 7 and compare the predicted labels from your code with labels you predicted in question 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "6b147a66b6e6e2844d6d949df291ba10",
     "grade": true,
     "grade_id": "cell-678ba5473c172ab2",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0] [0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "# knn(data_X, data_Y, query_X, dist_measure, k)\n",
    "query_Y_eu = knn(train_X, train_Y, test_X, 'euclidean', 3)\n",
    "query_Y_cos = knn(train_X, train_Y, test_X, 'cosine', 3)\n",
    "\n",
    "print(query_Y_eu, query_Y_cos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "51838594ab2dc23122ea112e979c404a",
     "grade": false,
     "grade_id": "cell-fbcce8e7e706c024",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### 9. (1 point) Implement an evaluation function that takes a vector of true labels and a vector of predicted labels and outputs classification accuracy and a confusion matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "31a5755c1c1c8dc1017009297764c329",
     "grade": false,
     "grade_id": "cell-286eff62194138af",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def evaluation(pred, truth, n_classes):\n",
    "    '''\n",
    "    Takes a set of predicted labels and ground truth labels, and compute the classification accuracy. \n",
    "    Input Parameters\n",
    "    ----------------\n",
    "    pred: a 1-D numpy array of integer values which refer to labels predicted from a classifier.\n",
    "    truth: a 1-D numpy array of integer values which refer to ground truth labels\n",
    "    n_classes: a number of classes in your dataset.\n",
    "\n",
    "    \n",
    "    Returns\n",
    "    -----------------\n",
    "    accuracy: a float number indicating the classification accuracy as a number in the range 0 to 1.\n",
    "    confusion: a n-D numpy array of confusion matrix with the shape of (n_classes, n_classes)\n",
    "\n",
    "    '''\n",
    "    correct_count = 0\n",
    "    confusion = np.zeros(shape=(n_classes, n_classes))\n",
    "    for i in range(len(truth)):\n",
    "        if pred[i] == truth[i]:\n",
    "            correct_count += 1\n",
    "        \n",
    "        # confusion matrix\n",
    "        confusion[truth[i], pred[i]] = confusion[truth[i], pred[i]] + 1 # inc box the represents the cross-section of truth&pred\n",
    "    \n",
    "    accuracy = correct_count/len(truth)\n",
    "    \n",
    "    return accuracy, confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6d2873cdc52c78caf984c2663660c323",
     "grade": true,
     "grade_id": "cell-055d8c616f5e3b64",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# you don't need to put anything here, this cell is for the autograder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ace6242b59d78893c63274222fbdead5",
     "grade": false,
     "grade_id": "cell-5c3d918a0aff8218",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### 10. (1 point) Now complete the *KNN_testing* function to test your KNN classifier on a real dataset. You can load the dataset by calling *load_dataset* provided below. It returns training set and testing set of two classes. Build a KNN classifier on the training set and evaulate it on the provided testing set using the functions you implemented in the previous question.\n",
    "\n",
    "* *NOTE: When running KNN, set K=2 and use euclidean distance*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e49798c530fa6ace5bf418a38348da22",
     "grade": false,
     "grade_id": "cell-22bc87173f8ebd45",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    \n",
    "    iris = load_iris()\n",
    "    data_X = iris.data\n",
    "    data_Y = iris.target\n",
    "    data_X_class1 = data_X[data_Y==1, :]\n",
    "    data_X_class2 = data_X[data_Y==2, :]\n",
    "    train_X = np.vstack((data_X_class1[:30, :], data_X_class2[:30, :]))\n",
    "    train_Y = np.array([0]*30+[1]*30)\n",
    "    test_X = np.vstack((data_X_class1[30:, :], data_X_class2[30:, :]))\n",
    "    test_Y = np.array([0]*20+[1]*20)\n",
    "\n",
    "    return train_X, train_Y, test_X, test_Y\n",
    "\n",
    "def KNN_testing():\n",
    "    \n",
    "    '''\n",
    "    Returns\n",
    "    -----------------\n",
    "    accuracy: a float number indicating the classification accuracy as a number in the range 0 to 1.\n",
    "    confusion: a 2-D numpy array of confusion matrix.\n",
    "    '''\n",
    "    \n",
    "    # data loading\n",
    "    train_X, train_Y, test_X, test_Y = load_dataset()\n",
    "    \n",
    "    # knn(data_X, data_Y, query_X, dist_measure, k)\n",
    "    pred_Y = knn(train_X, train_Y, test_X, 'euclidean', 2)\n",
    "    \n",
    "    # evaluation(pred, truth, n_classes)\n",
    "    accuracy, confusion = evaluation(pred_Y, test_Y, 2)\n",
    "    \n",
    "    return accuracy, confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "022cf1750be4a5c9456fb3efcb3aece6",
     "grade": true,
     "grade_id": "cell-54917582202f695d",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# you don't need to put anything here, this cell is for the autograder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.925, array([[19.,  1.],\n",
       "        [ 2., 18.]]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN_testing() # same as sklearn knn, so not too shabby"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "aaee0c6e5ce90b1fd4c16bc8d21f0a09",
     "grade": false,
     "grade_id": "cell-34d6e63bccb26d7c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Audio classification\n",
    "\n",
    "#### In the lecture, we have walked you through the procedure of door knock/phone rining classification. In the following questions, you are going to go through the same procedure, but with different dataset. In this homework, you are going to use ESC-50 [https://github.com/karoldvl/ESC-50] dataset. \n",
    "\n",
    "1. Open `./dataset/meta/esc50.csv` in the dataset. It contains a list of file names and their labels. While the csv files contains 2000 file names, you are going to use only two classes of audio events: *sneezing and snoring*. We included the audio files of *sneezing and snoring* in the homework (`./dataset/audio/`), so you do not need to download the dataset from the official website.\n",
    "\n",
    "2. As shown in `./dataset/meta/esc50.csv`, there are 40 examples per class and the 40 examples are split into 5 folds. You are going to use folds 1-3 as a training set and 4-5 as a testing set. Since each fold contains 8 examples and you are using two classes, you will end up with 48 training examples (24 sneezings, 24 snorings) and 32 testing examples (16 sneezings, 16 snorings)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b9e5a1045b2bd8be23b5a820a03e3e0b",
     "grade": false,
     "grade_id": "cell-a68a6fb9be0089c4",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### 11. (2 points) Implement a feature extraction function. It takes an audio file path, extract audio features, and outputs a single feature vector. \n",
    "\n",
    "* Extract [zero-crossing rate](https://librosa.github.io/librosa/generated/librosa.feature.zero_crossing_rate.html) and [spectral centroid](https://librosa.github.io/librosa/generated/librosa.feature.spectral_centroid.html) using librosa package (window length: 2048, hop size: 1024). \n",
    "* Do feature summarization to convert a series of feature vectors into a single feature vector. Use mean and delta-mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "b487eb7cdc402bb80830fdbeb6e04939",
     "grade": false,
     "grade_id": "cell-fb09bb52123dade8",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def feature_extraction(file_path):\n",
    "    '''\n",
    "    Takes an audio file path, read the audio (keep the original sampling rate), \n",
    "    extract audio features from the audio, and outputs a single feature vector containing\n",
    "    [mean-zero-crossing-rate, mean-delta-zero-crossing-rate, mean-spectral-centroid, mean-delta-spectral-centroid]\n",
    "    \n",
    "    Input Parameters\n",
    "    ----------------\n",
    "    file_path: a string indicating a path to an audio file.\n",
    "    \n",
    "    Returns\n",
    "    ----------------\n",
    "    feature_vector: a 1-D numpy array of an extracted feature vector.\n",
    "    '''\n",
    "    win_len = 2048\n",
    "    hop_len = 1024\n",
    "    file_wav, wav_sr = librosa.load(file_path) # load in audio and samplinf rate\n",
    "    \n",
    "    zero_crossing_rate = librosa.feature.zero_crossing_rate(y=file_wav, frame_length=win_len, hop_length=hop_len)\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=file_wav, sr=wav_sr, n_fft=win_len, hop_length=hop_len)\n",
    "    \n",
    "    # feature summ\n",
    "        # [mean-zero-crossing-rate, mean-delta-zero-crossing-rate, \n",
    "        # mean-spectral-centroid, mean-delta-spectral-centroid]\n",
    "    \n",
    "    # mean\n",
    "    mean_zcr = np.mean(zero_crossing_rate)\n",
    "    mean_sc = np.mean(spectral_centroid)\n",
    "    \n",
    "    # delta_mean\n",
    "    delta_zcr = []\n",
    "    delta_sc = []\n",
    "    for i in range(1,len(zero_crossing_rate)):\n",
    "        delta_zcr.append(zero_crossing_rate[i] - zero_crossing_rate[i-1])\n",
    "    \n",
    "    for i in range(1,len(spectral_centroid)):\n",
    "        delta_sc.append(spectral_centroid[i] - spectral_centroid[i-1])\n",
    "    \n",
    "    mean_delta_zcr = np.mean(delta_zcr)\n",
    "    mean_delta_sc = np.mean(delta_sc)\n",
    "    \n",
    "    feature_vector = [mean_zcr, mean_delta_zcr, mean_sc, mean_delta_sc]\n",
    "    \n",
    "#     raise NotImplementedError # delete this line when you add your solution\n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ad9b18cbf03ad56bab53fcb4fb982bf4",
     "grade": true,
     "grade_id": "cell-66ad6bd1b8a1d929",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# you don't need to put anything here, this cell is for the autograder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7f452255dde7e6077987a22ad0c222b3",
     "grade": false,
     "grade_id": "cell-8361a15f4c733c25",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### 12. (1 point) Implement following two functions: 1) a function constructing feature vectors from all the training and testing data and encoding labels of them and 2) a function recaling the feature vectors.\n",
    "   * To collect file names of all the data you need, you can use the provided function *collect_filenames*.\n",
    "   * For feature extraction, use *feature_extraction* function you built from the previous question.\n",
    "   * The labels should be encoded as an integer value: (Sneezing:0, snoring:1) \n",
    "   * Rescale each feature to a range (0, 1) using [sklearn.preprocessing.MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html).  \n",
    "   * The scaling factor should be learned from the **entire training set** including both sneezing and snoring class\n",
    "   * The scaling factor should **NOT** be learned from the **testing set** because we should assume that your classifer never have access to testing data before it is tested. Therefore, you first learn scaling factor from trianing set only and apply the learned scaler to both training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "39f47e781c7456c60494626939070658",
     "grade": false,
     "grade_id": "cell-46cf6da2521ae86b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def collect_filenames(path_to_esc50_csv):\n",
    "    \n",
    "    '''\n",
    "    Collect file names for training and testing set from `./dataset/meta/esc50.csv`. \n",
    "\n",
    "    Input Parameters\n",
    "    ----------------\n",
    "    path_to_esc50_csv: a string indicating a path to esc50.csv in ESC50 dataset.\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    ----------------\n",
    "    train_filenames: a dictionary containing file names of training set. \n",
    "                    Its keys are each class name: 'sneezing', 'snoring' \n",
    "    test_filenames: a dictionary containing file names of testing set. \n",
    "                    Its keys are each class name: 'sneezing', 'snoring' \n",
    "    '''\n",
    "    train_filenames = {'sneezing':[], 'snoring':[]}\n",
    "    test_filenames = {'sneezing':[], 'snoring':[]}\n",
    "    \n",
    "    with open(path_to_esc50_csv) as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            if row['category'] == 'sneezing':\n",
    "                if int(row['fold']) in [1, 2, 3]:\n",
    "                    train_filenames['sneezing'].append(row['filename'])\n",
    "                else:\n",
    "                    test_filenames['sneezing'].append(row['filename'])\n",
    "            if row['category'] == 'snoring':\n",
    "                if int(row['fold']) in [1, 2, 3]:\n",
    "                    train_filenames['snoring'].append(row['filename'])\n",
    "                else:\n",
    "                    test_filenames['snoring'].append(row['filename'])\n",
    "    \n",
    "    return train_filenames, test_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "0c9aeef69960e076aaece2b92c637a93",
     "grade": true,
     "grade_id": "cell-01853877278942d4",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def data_preperation():\n",
    "    \n",
    "    '''\n",
    "    construct feature vectors from all the training and testing data and encoding labels of them\n",
    "    \n",
    "    Returns\n",
    "    ----------------\n",
    "    train_X: a 2-D numpy array with a shape of (the number of training examples, the number of features).\n",
    "    train_Y: a 1-D numpy array containing integer labels for training examples.\n",
    "            Encode \"sneezing\" to 0 and \"snoring\" to 1.\n",
    "    \n",
    "    test_X: a 2-D numpy array with a shape of (the number of testing examples, the number of features).\n",
    "    test_Y: a 1-D numpy array containing integer labels for tesing examples.\n",
    "            Encode \"sneezing\" to 0 and \"snoring\" to 1.\n",
    "    '''\n",
    "\n",
    "    train_filenames, test_filenames = collect_filenames('./dataset/meta/esc50.csv')\n",
    "\n",
    "    \n",
    "    raise NotImplementedError # delete this line when you add your solution\n",
    "    \n",
    "    return train_X, train_Y, test_X, test_Y\n",
    "\n",
    "\n",
    "def feature_rescaling(train_X, test_X):\n",
    "    \n",
    "    '''\n",
    "\n",
    "    Input Parameters\n",
    "    ----------------\n",
    "    train_X: a 2-D numpy array with a shape of (the number of training examples, the number of features).\n",
    "    test_X: a 2-D numpy array with a shape of (the number of testing examples, the number of features).\n",
    "    \n",
    "    Returns\n",
    "    ----------------\n",
    "    train_rescaled_X: the rescaled version of train_X\n",
    "                    a 2-D numpy array with a shape of (the number of training examples, the number of features).\n",
    "    test_rescaled_X : the rescaled version of test_X\n",
    "                    a 2-D numpy array with a shape of (the number of testing examples, the number of features).\n",
    "    \n",
    "    '''\n",
    "    raise NotImplementedError # delete this line when you add your solution\n",
    "    \n",
    "    return train_rescaled_X, test_rescaled_X\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "94294a7c2c62034ca6e2fa4e8aa090d7",
     "grade": false,
     "grade_id": "cell-9e0275c6dbb694e3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### 13. (1 point) Your feature extractor outputs *mean-zero-crossing-rate, mean-delta-zero-crossing-rate, mean-spectral-centroid, mean-delta-spectral-centroid*. If you want to represent the data from the ESC-50 data set in a 2-d scatter plot, you'll need to pick just two of those features. Pick the pair of features that best separates sneezing examples from snoring examples. Plot the data using that pair of features. Be sure to make markers for dots different for different classes and to label the graph so we can tell which dots belong to which class. Label the figure's axes appropriately, so it is obvious which features you chose.\n",
    "\n",
    "* Note: Use the rescaled feature vectors from the previous question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "105e7f81acd683c195b1de7619cdea52",
     "grade": true,
     "grade_id": "cell-db068e04d772640c",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-0f00a5996478>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m \u001b[0;31m# delete this line when you add your solution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "raise NotImplementedError # delete this line when you add your solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "92fa15045e2b4158717c4933c2598332",
     "grade": false,
     "grade_id": "cell-bc2cebf3f1918c56",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### 14 (1 point) Test your KNN classifier on the testing examples and report its accuracy and confusion matrix. Use the functions you implemented in previous questions: *data_preperation*, *feature_rescaling*, *knn*,  and *evaluation* . Explain about your results. What do the accuracy and confusion matrix tell about your classifier?\n",
    "* Use all the extracted features (Mean-zcr, Delta-mean-zcr, Mean-sc, Delta-mean-sc)\n",
    "* Use the rescaled version of features from question 12\n",
    "* When running a KNN classifier, set K=1 and use euclidean distance as a distance measure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e38416371a12c660b0db2a361b4bf93a",
     "grade": true,
     "grade_id": "cell-8bf5236b322abcd2",
     "locked": false,
     "points": 0.5,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "raise NotImplementedError # delete this line when you add your solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "293c8bf34796a702ea6700a54368ee75",
     "grade": true,
     "grade_id": "cell-afc41edef458d8a5",
     "locked": false,
     "points": 0.5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7e0fe027f695cd61b7cd6ffd226bb255",
     "grade": false,
     "grade_id": "cell-638ae83eb574dd66",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### 15 (2 point) Now test your KNN classifier  with different values of K (1 to 5) and different distance measures (Euclidean and cosine) to find the setting which maximizes accuracy. Include a figure showing how accuracy changes with different combinations of K and distance measrure. The figure should include results from the 10 combinations (5 different values of K, 2 different distance metrics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "0a112a8f40a7ccb592f8a0da14a252f1",
     "grade": true,
     "grade_id": "cell-7e8c0443b32b6db6",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "raise NotImplementedError # delete this line when you add your solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "59d34009d21e8fab00169c8c1c951d83",
     "grade": false,
     "grade_id": "cell-c3192170a15bb292",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### 16 (2 point) Try other features provided in Librosa to improve your classifier. Implement a new feature extraction function that extracts those features. You can use new features, in addition to of zero-crossing-rate and spectral centroid or just replace them with new ones. What features improved classification the accuracy? Report classification accuracy of the new classifier on the testing set. How much do the new features improve the performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d3c3868d7ef006b7474de2b71bdb5ba3",
     "grade": true,
     "grade_id": "cell-c77e1c7f3f87f9c9",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "raise NotImplementedError # delete this line when you add your solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "5af46358652364978433b5e9bedd99e9",
     "grade": true,
     "grade_id": "cell-c5543d57deb012b0",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

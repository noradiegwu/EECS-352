{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d21ae598fa73c3edb1c78386db96c4aa",
     "grade": false,
     "grade_id": "cell-07683527464333de",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Homework 1 â€” (20 points)\n",
    "======\n",
    "### What to hand in\n",
    "1. A Jupyter notebook containing all code and output (figures and audio). We should be able to evaluate the file to reproduce all output. \n",
    "1. Any other data that we tell you to save to a file (e.g. audio files).\n",
    "\n",
    "### How to hand it in\n",
    "1. Compress all of the files specified into a .zip file. \n",
    "1. Name the file in the following manner, firstname_lastname_hw1.zip. For example, Bryan_Pardo_hw1.zip. \n",
    "1. Submit this .zip file via Canvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "846915b956862131ac234c1e75435b34",
     "grade": false,
     "grade_id": "cell-776ee25997ea8a12",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Run this code block 1st, to import likely needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d26dd57b717d6040474aa335310d6b1a",
     "grade": false,
     "grade_id": "cell-67643ce7418809d1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This line imports most packages you'll need. You may need to import others (eg random and cmath)\n",
    "import IPython, numpy as np, scipy as sp, matplotlib.pyplot as plt, matplotlib, sklearn, librosa, cmath,math\n",
    "from IPython.display import Audio\n",
    "\n",
    "# This line makes sure your plots happen IN the webpage you're building, instead of in separate windows.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "fdb843d9c279ee14fecc344bf6028957",
     "grade": false,
     "grade_id": "cell-43eae4f7713048be",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Sampling Culture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4188e30bf930a9759d1b44a71e7dd702",
     "grade": false,
     "grade_id": "cell-c3422f6015430dd1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### 1. (1 point) A lot of modern music is remix music, building on existing recordings. Here are several examples: Cardi B \"I Like It\",  Coolio's \"Gangster's Paradise\", Kanye West's \"Gold Digger\", Drake's \"Nice for What\". Name the artist and title of a song that is prominently sampled in each of these songs.  Listen to each song you mention that was sampled. Did you discover an artist or a song that you like? If so, which one(s)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "322a7b82d340f550efb2fc1420fefb3c",
     "grade": true,
     "grade_id": "question1",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "Cardi B \"I Like It\" - Pete Rodriguez \"I Like It Like That\"\n",
    "Coolio \"Ganster's Paradise\" - Stevie Wonder, \"Pastime Paradise\"\n",
    "Kanye West \"Gold Digger\" - Ray Charles \"I Got a Woman\"\n",
    "Drake \"Nice For What\" - Lauryn Hill \"Ex-Factor\"\n",
    "\n",
    "I'd already known and loved all of these artists before, except Pete Rodriguez (who is amazing!). But, I just added \"Ex-Factor\" to my current playlist..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6c6dd036bbd7d4889d75e7f03960d57f",
     "grade": false,
     "grade_id": "cell-d4bce648289af0d9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## The Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d891316bfe3490589dd1444c52cb84d7",
     "grade": false,
     "grade_id": "cell-aef2ad8dc4d80056",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### 2. (1 point) Explain, in your own words, how the cochlea detects and encodes the frequency and amplitude content of sound. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "b1b29aa75ee50e3072811730a010b15b",
     "grade": true,
     "grade_id": "question2",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "SOund waves vibrate the eardrum at different frequencies, which then pushes the tiny ear bones, that then move fluid inside the cochlea, which then vibrates the hair cells inside the organ of corti. These hair cells resonate at different frequenies. Higher frequencies are sensed at the base of the cochlea and lower frequencies are sensed at the apex.  So, the section of the fibers that is vibrating relates to the frequency(ies) that you hear. Louder (generally, higher amplitude) sounds move hair cells more which generates more frequent action potentials that the brain can sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "bf2019562cab3e32f1f822f0d0dd5c16",
     "grade": false,
     "grade_id": "cell-c2836399876b50a5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### 3-A. (0.5 point)   The sample rate of telephone audio (8 kHz) and CD quality audio (44.1 kHz) are very different. Express in Hz the highest frequency sound you can represent (without aliasing) at each of these two sample rates. How do these frequencies compare to the highest frequency a typical human with no hearing loss can hear?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "bfb76aa5afeaed8a031fd29da9b1cd65",
     "grade": true,
     "grade_id": "question3a",
     "locked": false,
     "points": 0.5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "Telephone sampling (8Hz) - 4 Hz sound max can be sampled w/o aliasing\n",
    "CD sampling (44.1Hz) - 22.05Hz sound max can be sampled w/o aliasing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "79f86149878f64ad539f0449e4042a3f",
     "grade": false,
     "grade_id": "cell-e2d703e5f385121a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### 3-B. (0.5 point) Sample rate isn't the only difference between CD and telephone audio. Express in dB the dynamic range (range of loud to soft) of 8 bit audio (telephone quality) and 16 bit audio (CD quality).  How many bits would one need to exceed the dynamic range of human hearing? Use the formula for voltage dB (i.e.   $20*log_{10}(X/X_{ref})$ )  Show your work.  (Hint: what is the difference between the smallest number you can represent in 8 bits and the largest number?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "47097aadbef99c6bb8af6bb0c21ff553",
     "grade": true,
     "grade_id": "question3b_0",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c6ca164ef1a22e427e00e5d53d97054c",
     "grade": false,
     "grade_id": "question3b_1",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# assign your answers to these variables\n",
    "range8 = None\n",
    "range16 = None\n",
    "range_diff = None\n",
    "n_bits_human = None\n",
    "\n",
    "# your code goes here\n",
    "x_ref = 1 # lowest quantifiable/identifiable/pick-up-able number in the range (not 0 cause can't hear zero)\n",
    "human_dynamic_range = 120 # dB - pain threshold\n",
    "\n",
    "def db_range(bits):\n",
    "    return 20 * math.log((2**bits/x_ref), 10)\n",
    "\n",
    "def db_to_bits(db):\n",
    "    # log_10 (2^x) = db  --> 2^x = 10^db; exponent conversion\n",
    "    # x * log_2(2) = log_2(10^db); use log on both sides to move x out of exponenet\n",
    "    # x = log_2(10^db); log base 2 (2) = 1\n",
    "    return math.ceil(math.log(10**db, 2) / 20) # ceil, because you can't use e.g. 20.1 bits\n",
    "\n",
    "range8 = db_range(8) # ~48dB\n",
    "range16 = db_range(16) # ~96dB\n",
    "range_diff = range16 - range8\n",
    "n_bits_human = db_to_bits(human_dynamic_range + 1) # + 1 to ~exceed~ human hearing dynamic range --> 21 bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5ea5fef1e3d51e20238d4326bdee8592",
     "grade": true,
     "grade_id": "question3b_1_0",
     "locked": true,
     "points": 0.2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# you don't need to put anything here, this cell is for the autograder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8416e119f1bd3f1eaac37ecd05f72faf",
     "grade": true,
     "grade_id": "question3b_1_2_",
     "locked": true,
     "points": 0.2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# you don't need to put anything here, this cell is for the autograder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "35a861a92c040939a8037bc2ac405d3f",
     "grade": true,
     "grade_id": "cell-eb663bc6723b644b",
     "locked": true,
     "points": 0.1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# you don't need to put anything here, this cell is for the autograder "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "98069dcb096b47364cb22794f94d5b6e",
     "grade": false,
     "grade_id": "cell-964e403dc5719b33",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### 4. (1 point) Make a function to generate sinewaves.  Write a function to plot an audio signal and use it to display the generated sinewave (you can write your own plotting function or use the \"plot_audio\" function provided in the previous homework). Label the figure's axes appropriately. Test the function for a simple case (e.g. a sinewave of frequency 10 Hz and length 1 sec, sampled at a rate of 100 Hz).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "67a53b445635b09e36b94163c4972121",
     "grade": false,
     "grade_id": "question4_0",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def make_sinewave(f, t, sr):\n",
    "    \"\"\"    \n",
    "    Parameters\n",
    "    ----------\n",
    "    f:  float\n",
    "        Frequency of sine wave\n",
    "    t:  float\n",
    "        Duration in seconds\n",
    "    sr: int\n",
    "        Sample rate\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray \n",
    "        Array of floats containing the signal\n",
    "    \"\"\"\n",
    "    \n",
    "    # your code goes here\n",
    "    \n",
    "    raise NotImplementedError # delete this line when you add your solution\n",
    "    \n",
    "# plot_audio from HW0\n",
    "def plot_audio(x, sr, figsize=(16,4)):\n",
    "    \"\"\"\n",
    "    A simple audio plotting function\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x: np.ndarray\n",
    "        Audio signal to plot\n",
    "    sr: int\n",
    "        Sample rate\n",
    "    figsize: tuple\n",
    "        A duple representing the figure size (xdim,ydim)\n",
    "    \"\"\"\n",
    "    length = float(x.shape[0]) / sr\n",
    "    t = np.linspace(0,length,x.shape[0])\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.plot(t, x)\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "536a4bb821eab1b8fc3f922e723b6967",
     "grade": true,
     "grade_id": "cell-97718e5de1742156",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# you don't need to put anything here, this cell is for the autograder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "f40777e993291380a326ce10cceef867",
     "grade": false,
     "grade_id": "question4_1",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_audio(x, sr, figsize=(16,4)):\n",
    "    \"\"\"\n",
    "    A simple audio plotting function\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x: np.ndarray\n",
    "        Audio signal to plot\n",
    "    sr: int\n",
    "        Sample rate\n",
    "    figsize: tuple\n",
    "        A duple representing the figure size (xdim,ydim)\n",
    "    \"\"\"\n",
    "    \n",
    "    # your code goes here\n",
    "    raise NotImplementedError # delete this line when you add your solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d5be2e077024a42b0a239bea61b48c68",
     "grade": true,
     "grade_id": "question4_2",
     "locked": false,
     "points": 0.5,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# this is the cell where you should demonstrate your working make_sinewave and plot_audio functions\n",
    "# your code goes here\n",
    "raise NotImplementedError # delete this line when you add your solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b1dfb0cff9ad06f020a87f2bbef00912",
     "grade": false,
     "grade_id": "cell-99e7130f6ac5be2d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### 5. (1 point) The case of the missing fundamental is where a sound seems to have a pitch at frequency F0, but has no energy at this frequency.  Instead all the frequency is at integer multiples of F0. Write code to build an audio example that illustrates the case of the missing fundamental: First play a harmonic sound with 10 harmonics (including F0) that all have the same amplitude.  Let's make it the C one octave below Middle C on the piano: 131 Hz. Then, successively remove each harmonic, starting from the lowest, to the highest (F0, then F1....etc). How many harmonics had to disappear before it sounded like the pitch changed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "6988b141937f5b9622886c03e62e3338",
     "grade": true,
     "grade_id": "cell-ce3834d79f146663",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a30515aefb9c8c1aa515d1c594d923c2",
     "grade": true,
     "grade_id": "cell-d1d0593b28001144",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "raise NotImplementedError # delete this line when you add your solution\n",
    "\n",
    "# plot and play\n",
    "plot_audio(soundseries, sr)\n",
    "Audio(soundseries, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d7560c289818ec546012cbb0d06a67e1",
     "grade": false,
     "grade_id": "cell-7a49e0eb00d61565",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### 6. (1 point) Implement a simple function to express the Root Mean Squared Amplitude of a signal encoded as an array, in dB, with respect to a reference value (review the lecture on amplitude, slides no. 5-8)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "b1cca57fc82d9ff3eef1de720cb51120",
     "grade": false,
     "grade_id": "cell-24106c113ebb198d",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def rms_db(signal, reference):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    signal:  np.ndarray \n",
    "        Array of floats containing the signal\n",
    "    reference:  float\n",
    "        A reference amplitude to compare to \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        a value in dB, given the reference value\n",
    "    '''\n",
    "    # your code goes here\n",
    "    raise NotImplementedError # delete this line when you add your solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a5e1dd150967e126a4f467a7f85fcc19",
     "grade": true,
     "grade_id": "cell-108ebeb6405a41b7",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# you don't need to put anything here, this cell is for the autograder "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "52a2457b537110d9ade11ee06ca9d8c0",
     "grade": false,
     "grade_id": "cell-03bb68ff876c3335",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### 7. (1 point) Masking is where one sine wave makes a softer sine wave of nearby frequency inaudible. In class, you learned that our frequency sensitivity is related to the log of the frequency. This means that a lower tone will mask a broader frequency range above it than it does below it. We're going to explore that in this problem.  Write code that does the following: Make a sine wave at 440 Hz.  Now, make a 2nd sine wave that is 30 dB softer and 430 Hz. Play them simultaneusly. Now repeatedly lower the frequency of the softer sine wave by 20 Hz. Listen to the resulting series of paired sounds. At what frequency does it become really obvious that there are two sine waves?  Now try it the other direction.  Make the softer tone at 450 Hz and vary it upward (maybe take 40 Hz steps, in the upward direction) each time. Now at what frequency does the softer tone become obvious when the softer tone gets higher instead of lower? Do this experiment with decent headphones in a quiet room. Don't use your laptop speakers in a noisy place.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "7b558e928a2982285026e42d10ee4bf7",
     "grade": true,
     "grade_id": "cell-ee725911844f7836",
     "locked": false,
     "points": 0.5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "fb10021b976e379117a762c53a65b849",
     "grade": true,
     "grade_id": "cell-2eef06abfe850633",
     "locked": false,
     "points": 0.5,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "raise NotImplementedError # delete this line when you add your solution\n",
    "plot_audio(soundseries,sr)\n",
    "Audio(soundseries, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "551dde062859c210c5ad1a6d41a2181b",
     "grade": false,
     "grade_id": "cell-d70ffda0a62b7190",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Using the Fourier transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5520da1b0ba87571fbc86421efe4d60e",
     "grade": false,
     "grade_id": "cell-9492fc13c4440536",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### We're now going to look at using the Fourier transform to create representations for sound that let you analyze it and manipulate. The work you do in the following sections will be much easier if you use the fft and ifft functions from scipy.  See the following link for documentation on them. \n",
    "http://docs.scipy.org/doc/scipy/reference/tutorial/fftpack.html "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8085d63c508da9f26c95459ed82dbbfe",
     "grade": false,
     "grade_id": "cell-758cfc998009bae2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### 8. (one point) Let's look at a signal to see how the Fourier transform lets us understand it more easily. The choice of windowing function for your FFT is an important one. In this problem, we are going to investigate the effect of windowing on the spectra of sine waves. Write a function to compute and plot the log-magnitude spectrum of a signal. Your function must receive the number of frequency samples as an input (there is an optional parameter in scipy's fft that lets you specify how many points the FFT has). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c5285ec8a1c1a1dd3ce25727cfdd0a0c",
     "grade": true,
     "grade_id": "cell-41a9c65c2ec42a0f",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def audio_spectrum(sig, win_len, win_type, Nfft):\n",
    "    \"\"\"\n",
    "    Computes the spectrum of an audio signal\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sig: np.ndarray\n",
    "        Audio signal \n",
    "    win_len: int\n",
    "        Length of the signal for spectrum computation (in samples)\n",
    "    win_type: string\n",
    "        Determines the window type including 'rectangular' and 'hann'\n",
    "    Nfft: int\n",
    "        Number of frequency-domain samples \n",
    "        \n",
    "   Returns\n",
    "    -------\n",
    "    a numpy array of the magnitude (absolute value) log spectrum.\n",
    "\n",
    "    \"\"\"    \n",
    "    # your code goes here\n",
    "    raise NotImplementedError # delete this line when you add your solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. (1 point) Make an audio signal composed of 2 sine waves at 100 and 250 Hz. The sample rate should be 1000 Hz. Now compute the spectrum of the signal using a rectangular window of length 64 samples. In this part we set the number of FFT points to the same value as the window length. Then compute the spectrum using a a Hann window (from scipy.signal). Plot both spectra on the same axis. Compare the two plots. Be sure to label the frequency dimension correctly (horizontal = frequency in Hz) with the correct units. Be sure to label your two lines so we can tell which is which."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "40a0cb25c5d91176b24b03a51874fe75",
     "grade": true,
     "grade_id": "cell-1e84601afd3f9e64",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "raise NotImplementedError # delete this line when you add your solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "73e3b0f50ebccad643d7b95770936d0c",
     "grade": false,
     "grade_id": "cell-85137b817a701a09",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### 10. (1 point) Which  windowing approach from the previous question gives a more accurate visualization of the signal contents, windowing the signal with a rectangular window or with a Hann window?  What is the underlying reason? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "f2733780679f2ecaa8f6574583e8781f",
     "grade": true,
     "grade_id": "cell-d582636880de083b",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d4282ef30a19ebf2c99e3fa44ee095b6",
     "grade": false,
     "grade_id": "cell-41fda9f6ca7c7e84",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### 11. (1 point)  When you calculate a FFT with more points than are in the signal, zeros are added to the input signal and interpolation is performed on the output signal. In general, zero-padding in the time domain is equivalent to creating new analysis bins in between original bins in the frequency domain. This often gives us a more accurate view of the frequency content in the signal.  We're going to do that here. Do everything exactly like you did in question 9....except increase the number of FFT points (Nfft) to 256. Note...keep the window length win_len the same, just vary Nfft. \n",
    "\n",
    "#### What are some of differences you notice in this plot compared to the previous one? \n",
    "\n",
    "You can read more about the effect of zero-padding on the frequency-domain representation in the follwing pages:\n",
    "\n",
    "http://www.dsprelated.com/freebooks/sasp/Zero_Padding_Time_Domain.html\n",
    "\n",
    "http://dspguru.com/dsp/howtos/how-to-interpolate-in-time-domain-by-zero-padding-in-frequency-domain\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e94920728c59d9760e541898476e026b",
     "grade": true,
     "grade_id": "cell-aa32c264ce5505db",
     "locked": false,
     "points": 0.25,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "fa8c039ae70b83bd98984dbb9601705b",
     "grade": true,
     "grade_id": "cell-d3034b89329619e7",
     "locked": false,
     "points": 0.75,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "raise NotImplementedError # delete this line when you add your solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d816e4aac57f93f541f1feabaf226bc5",
     "grade": false,
     "grade_id": "cell-427c8d094969f86b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### 12. (1 point). What is the pitch (in Hz) of the lowest note played by an in-tune piano using equal temperment tuned at A440? What is the pitch (in Hz) of the highest note? Now, given these numbers, assume you're recording at 44100 Hz (CD quality audio). Give a window length (in samples) so that the spacing between frequencies of analysis of a fast Fourier transform (the fft function you call to make the spectrogram) is low enough to capture the lowest note on the piano.  Remember, the lowest non-zero frequency of analysis is going to be equal to the spacing between the frequencies of analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "32f01ef4aecf02ae5ad7267a3b588fc4",
     "grade": false,
     "grade_id": "cell-ba19fa2989085d98",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "window_length = None\n",
    "# your code goes here\n",
    "raise NotImplementedError # delete this line when you add your solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e30b6d29632b126437b461a2f4d008bd",
     "grade": true,
     "grade_id": "cell-82ed455c9d11d107",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# you don't need to put anything here, this cell is for the autograder "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "dc1480e5de7a2478802975266409e0c2",
     "grade": false,
     "grade_id": "cell-3316127d101f083f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### 13. (2 points) Make a short term Fourier transform (STFT) function. Use the fft and ifft functions from scipy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "3ff241361c85cda84b94d5027aae8b2e",
     "grade": true,
     "grade_id": "cell-5ae0d1451120468b",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from scipy.fftpack import fft\n",
    "from scipy.signal import hann\n",
    "\n",
    "def stft(signal, window_size, hop_size, window_type = 'hann'):\n",
    "    \"\"\"\n",
    "    Computes the short term fourier transform of a 1-D numpy array, where the array \n",
    "    is windowed into a set of subarrays, each of length window_size. The distance between\n",
    "    window centers (in samples) is given by hop_size. The type of window applied is\n",
    "    determined by window_type. This returns a 2-D numpy array where the ith column\n",
    "    is the FFT of the ith window. Each column contains an array of complex values.\n",
    "    \n",
    "    Input Parameters\n",
    "    ----------------\n",
    "    signal: The 1-d (complex or real) numpy array containing the signal\n",
    "    window_size: an integer scalar specifying the number of samples in a window\n",
    "    hop_size: an integer specifying the number of samples between the start of adjacent windows\n",
    "    window_type: a string specifying one of two \"hann\" or \"rectangular\"\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    a 2D numpy array of complex numbers where the array column is the FFT of the ith window,\n",
    "    and the jth element in the ith column is the jth frequency of analysis.\n",
    "    \"\"\"\n",
    "    # your code goes here\n",
    "    raise NotImplementedError # delete this line when you add your solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "04b9261b4bf6265cdb1c9ca5eb348f9e",
     "grade": true,
     "grade_id": "cell-16a6b95029f1862d",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# you don't need to put anything here, this cell is for the autograder "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b7a6949d028481739d898c46d5500704",
     "grade": false,
     "grade_id": "cell-c9c7a50974477a41",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### 14. (2 points) Make an inverse STFT function to rebuild the original audio signal, using overlap & add resynthesis. You don't need to use a window function here.\n",
    "\n",
    "Note: we are not using a synthesis window for this exercise. However, keep in mind that in general it's recommended to weight the inverse Fourier transform of each frame by the same window function used for generating the spectrogram at each step of overlap & add (a.k.a. weighted overlap & add). The synthesis window helps reducing the effect of impulsive noise caused by modifying the audio spectrogram. \n",
    "\n",
    "See also https://ccrma.stanford.edu/~jos/sasp/Weighted_Overlap_Add.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "0fbbd138e41db1dc7a7951c980caa144",
     "grade": true,
     "grade_id": "cell-0b7c3c0a5f2f7fb6",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from scipy.fftpack import ifft\n",
    "\n",
    "def istft(X, hop_size):\n",
    "    \"\"\"\n",
    "    Takes a 2-D numpy array representing an STFT of some signal, where stft[i] \n",
    "    is the FFT of the ith window as input and stft[i,k] is the kth frequency of analysis.\n",
    "    Performs an inverse FFT on each window and then does overlap & add resynthesis to rebuild \n",
    "    the original signal the STFT was built from.\n",
    "    \n",
    "    Input Parameters\n",
    "    ----------------\n",
    "    X: a 2-D numpy array of complex numbers representing an STFT, where the ith \n",
    "    column is the FFT of the ith window, and the jth row is the jth frequency of analysis.\n",
    "        \n",
    "    hop_size: an integer specifying the number of samples between the start of adjacent windows.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    a 1-d numpy array of (possibly complex) values representing the original signal used to make X\n",
    "    \"\"\"\n",
    "    # your code goes here\n",
    "    raise NotImplementedError # delete this line when you add your solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e31dfb4b9db45f8d53dfa536970ba882",
     "grade": true,
     "grade_id": "cell-b342b4d0f1f20087",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# you don't need to put anything here, this cell is for the autograder "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f0a7e3bf90d6ac4340fe5db46732c495",
     "grade": false,
     "grade_id": "cell-874947e7aac0ccad",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### 16. (2 points) Write a test to show that your code in 13 and 14 works. One obvious thing that comes to mind is  performing the STFT on a sound, performing the inverse STFT and then measuring the difference between the original signal and the one that went through the STFT and inverse STFT. Being more specific I'd do something like this...\n",
    "\n",
    "1. Make a signal you understand (e.g. a sinewave or two) \n",
    "1. For each signal $s$, run it through stft and then istft, to generate a reconstruction $s'$\n",
    "1. Measure the sum of squared errors (sse) between s and s' as follows $ sse = \\sum_{n=1}^{N} (s(n)-s'(n))^2$\n",
    "1. Plot it (ie plot both your $s$ and $s'$) to see the differences\n",
    "\n",
    "<i>HINTS: \n",
    "\n",
    "* The istft returns an array of complex values. As long as the imaginary component of all these values is 0, you're fine. Just take the real portion of the numbers and use those.\n",
    "\n",
    "* To numerically measure your reconstruction error, pick a rectangular window and a hop_size = window_size.\n",
    "\n",
    "* If doing stft and then istft ends up making a signal a TOUCH shorter (i.e. the length of a hop, as measured in samples), that's OK. But no more than that.\n",
    "\n",
    "* If you make your hop size 1/2 your window size and pick the Hann window, you should see a little reconstruction error at the very beginning and the very end, but other than that, it should be perfect.  Try it with a hop size = window size and see how that looks.\n",
    "\n",
    "* If you use rectangular windows with a hop size 1/2 your window size, signal reconstruction should be fine the very beginning and very end, but 2x louder throughout the middle.. Try it with a hop size = window size and see how that looks.  \n",
    "</i>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "3151a4b2bca4addb5beb5668c06417bf",
     "grade": true,
     "grade_id": "cell-87a25e645209fbcd",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "ec592e7842a8bff199880368df55afbc",
     "grade": true,
     "grade_id": "cell-fb45f5e092aabca4",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "raise NotImplementedError # delete this line when you add your solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1fbb88ece5fa2391d327831404470c91",
     "grade": false,
     "grade_id": "cell-77a252091254c115",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### 15. (2 points) Write a function to display a magnitude spectrogram of an audio signal. Magnitude must be in dB. Correct frequencies must be displayed. Display only frequencies up to the Nyquist rate.  Time must be displayed in seconds. Frequency needs to be on the vertical dimension. Time must be on the horizontal dimension. Magnitude must be encoded by color/brightness. You cannot use any functions in librosa to do this.  In the 2nd code box (below), write a little test to display your spectrogram working.\n",
    "\n",
    "<i>HINTS \n",
    "* You may need to rotate your axes to get the visual results that we are looking for. Experiment with np.fliplr or np.rot90.\n",
    "    \n",
    "* To plot things, I used plt.pcolor and plot.colorbar. \n",
    "\n",
    "* For visuzualization, it is often helpful to use the Hann window, instead of the rectangular one. It typically makes it easier to see the frequency content\n",
    "\n",
    "</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "01af2f5cc4bc29660c442d26735d4318",
     "grade": true,
     "grade_id": "cell-717ee73c3e871aa0",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def spectrogram(signal, window_size, hop_size, sample_rate, window_type = 'hann', display = 1 ):\n",
    "    \"\"\"\n",
    "    Computes the short term fourier transform of a 1-D numpy array, where the array \n",
    "    is windowed into a set of subarrays, each of length window_size. The distance between\n",
    "    window centers (in samples) is given by hop_size. The type of window applied is\n",
    "    determined by window_type. This creates a 2-D numpy array where the ith column\n",
    "    is the FFT of the ith window. Each column contains an array of complex values.\n",
    "    It then creates a magnitude spectrogram of the signal and plots it on the screen.\n",
    "    Here, the vertical dimension is frequency (in Hz), the horizontal dimension is time\n",
    "    (in seconds), brightness corresponds to amplitude (in dB). Only frequencies up to\n",
    "    the Nyquist rate are displayed.\n",
    "    \n",
    "    Input Parameters\n",
    "    ----------------\n",
    "    signal: The 1-d (complex or real) numpy array containing the signal\n",
    "    window_size: an integer scalar specifying the number of samples in a window\n",
    "    hop_size: an integer specifying the number of samples between the start of adjacent windows\n",
    "    sample_rate: an integer giving the sample rate of the input signal, in Hz\n",
    "    window_type: a string specifying one of two \"hann\" or \"rectangular\"\n",
    "    display: an integer. If set to 1, it plots the spectrogram. Else it does not.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    an output tuple with 3 items\n",
    "    \n",
    "    sgram:  a 2-D numpy array of real-valued numbers that contains the magnitude spectrogram\n",
    "           sgram[t,f] is the magnitude at time t and frequency f. This only contains values\n",
    "           up to the nyquist frequency\n",
    "    times: a 1-D numpy array of non-negative real-values that gives the times,  \n",
    "           times[t] gives the start time of the tth window in seconds\n",
    "    freqs: a 1-D numpy array  of non-negative real values. freqs[f] gives the fth\n",
    "           frequency of analysis in Hz, up to the nyquist frequency\n",
    "           \n",
    "    Calling Example\n",
    "    ---------------\n",
    "    sgram,times,freqs = spectrogram(signal, window_size, hop_size, sample_rate )\n",
    "\n",
    "    \"\"\" \n",
    "    # your code goes here\n",
    "    raise NotImplementedError # delete this line when you add your solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "7890b4e6d672dc51fb9a6feb83a84b30",
     "grade": true,
     "grade_id": "cell-8f0cd2fcbda34637",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "raise NotImplementedError # delete this line when you add your solution"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
